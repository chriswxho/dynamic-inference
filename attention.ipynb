{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29d5754f-9bea-4dea-ab04-56f28b1fe390",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "from dpt.plmodels import InteriorNetDPT\n",
    "from data.InteriorNetDataset import InteriorNetDataset\n",
    "from util.misc import visualize_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6931e1a1-1fa8-43f4-8aca-0a41153f4087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device name: cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'device name: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"cpu\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d93dc16-4079-4317-bc9e-8754cef4e088",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k8s paths\n",
    "k8s = False\n",
    "k8s_repo = r'opt/repo/dynamic-inference'\n",
    "k8s_pvc = r'christh9-pvc'\n",
    "\n",
    "# path settings\n",
    "model_path = 'weights/dpt_hybrid_nyu-2ce69ec7.pt'\n",
    "dataset_path = 'video_inference_common/resources'\n",
    "logs_path = 'train-logs'\n",
    "\n",
    "# checkpoint_name = 'version_290'\n",
    "\n",
    "if k8s:\n",
    "    model_path = os.path.join(k8s_pvc, 'dpt-hybrid-nyu.pt')\n",
    "    dataset_path = os.path.join(k8s_repo, dataset_path)\n",
    "    logs_path = os.path.join(k8s_pvc, logs_path)\n",
    "    \n",
    "#     checkpoint_dir = os.path.join(logs_path, 'finetune', checkpoint_name, 'checkpoints')\n",
    "    \n",
    "    os.chdir('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "127d9645-77fb-49bd-9911-a0cf92d49451",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InteriorNetDPT(batch_size=1, \n",
    "                       lr=0, \n",
    "                       num_epochs=0, \n",
    "                       model_path=model_path,\n",
    "                       enable_attention_hooks=True)\n",
    "\n",
    "model.to(device)\n",
    "model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbbaa33d-21ee-45f6-a906-1e03243343dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = InteriorNetDataset(dataset_path, split='val', \n",
    "                             transform='default', subsample=True)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "881fea78-9ab6-4948-874c-d0acd8462adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53592b27-e86f-4294-a177-72e46f276446",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        im, depth = batch['image'].to(device), batch['depth'].to(device)\n",
    "        out = model(im).squeeze(0)\n",
    "        \n",
    "        visualize_attention(im, model.model, out, 'dpt_hybrid', (20,20))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
