{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ac0af7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import util.io\n",
    "\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "from dpt.models import DPTDepthModel\n",
    "from dpt.midas_net import MidasNet_large\n",
    "from dpt.transforms import Resize, NormalizeImage, PrepareForNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f99e1113",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_path = 'input'\n",
    "output_path = 'output_monodepth'\n",
    "model_path = 'weights/dpt_hybrid_nyu-2ce69ec7.pt'\n",
    "model_type = 'dpt_hybrid'\n",
    "optimize = True\n",
    "\n",
    "runs = 500\n",
    "timings = np.zeros((runs,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4b16570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cpu\n"
     ]
    }
   ],
   "source": [
    "# select device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"device: %s\" % device)\n",
    "\n",
    "# load network\n",
    "if model_type == \"dpt_large\":  # DPT-Large\n",
    "    net_w = net_h = 384\n",
    "    model = DPTDepthModel(\n",
    "        path=model_path,\n",
    "        backbone=\"vitl16_384\",\n",
    "        non_negative=True,\n",
    "        enable_attention_hooks=False,\n",
    "    )\n",
    "    normalization = NormalizeImage(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "elif model_type == \"dpt_hybrid\":  # DPT-Hybrid\n",
    "    net_w = net_h = 384\n",
    "    model = DPTDepthModel(\n",
    "        path=model_path,\n",
    "        backbone=\"vitb_rn50_384\",\n",
    "        non_negative=True,\n",
    "        enable_attention_hooks=False,\n",
    "    )\n",
    "    normalization = NormalizeImage(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "elif model_type == \"dpt_hybrid_kitti\":\n",
    "    net_w = 1216\n",
    "    net_h = 352\n",
    "\n",
    "    model = DPTDepthModel(\n",
    "        path=model_path,\n",
    "        scale=0.00006016,\n",
    "        shift=0.00579,\n",
    "        invert=True,\n",
    "        backbone=\"vitb_rn50_384\",\n",
    "        non_negative=True,\n",
    "        enable_attention_hooks=False,\n",
    "    )\n",
    "\n",
    "    normalization = NormalizeImage(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "elif model_type == \"dpt_hybrid_nyu\":\n",
    "    net_w = 640\n",
    "    net_h = 480\n",
    "\n",
    "    model = DPTDepthModel(\n",
    "        path=model_path,\n",
    "        scale=0.000305,\n",
    "        shift=0.1378,\n",
    "        invert=True,\n",
    "        backbone=\"vitb_rn50_384\",\n",
    "        non_negative=True,\n",
    "        enable_attention_hooks=False,\n",
    "    )\n",
    "\n",
    "    normalization = NormalizeImage(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "elif model_type == \"midas_v21\":  # Convolutional model\n",
    "    net_w = net_h = 384\n",
    "\n",
    "    model = MidasNet_large(model_path, non_negative=True)\n",
    "    normalization = NormalizeImage(\n",
    "        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "else:\n",
    "    assert (\n",
    "        False\n",
    "    ), f\"model_type '{model_type}' not implemented, use: --model_type [dpt_large|dpt_hybrid|dpt_hybrid_kitti|dpt_hybrid_nyu|midas_v21]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2deafcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Compose(\n",
    "    [\n",
    "        Resize(\n",
    "            net_w,\n",
    "            net_h,\n",
    "            resize_target=None,\n",
    "            keep_aspect_ratio=True,\n",
    "            ensure_multiple_of=32,\n",
    "            resize_method=\"minimal\",\n",
    "            image_interpolation_method=cv2.INTER_CUBIC,\n",
    "        ),\n",
    "        normalization,\n",
    "        PrepareForNet(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86327497",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DPTDepthModel(\n",
       "  (pretrained): Module(\n",
       "    (model): VisionTransformer(\n",
       "      (patch_embed): HybridEmbed(\n",
       "        (backbone): ResNetV2(\n",
       "          (stem): Sequential(\n",
       "            (conv): StdConv2dSame(3, 64, kernel_size=(7, 7), stride=(2, 2), bias=False)\n",
       "            (norm): GroupNormAct(\n",
       "              32, 64, eps=1e-05, affine=True\n",
       "              (act): ReLU(inplace=True)\n",
       "            )\n",
       "            (pool): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=True)\n",
       "          )\n",
       "          (stages): Sequential(\n",
       "            (0): ResNetStage(\n",
       "              (blocks): Sequential(\n",
       "                (0): Bottleneck(\n",
       "                  (downsample): DownsampleConv(\n",
       "                    (conv): StdConv2dSame(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                    (norm): GroupNormAct(\n",
       "                      32, 256, eps=1e-05, affine=True\n",
       "                      (act): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (conv1): StdConv2dSame(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm1): GroupNormAct(\n",
       "                    32, 64, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv2): StdConv2dSame(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm2): GroupNormAct(\n",
       "                    32, 64, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv3): StdConv2dSame(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm3): GroupNormAct(\n",
       "                    32, 256, eps=1e-05, affine=True\n",
       "                    (act): Identity()\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                  (act3): ReLU(inplace=True)\n",
       "                )\n",
       "                (1): Bottleneck(\n",
       "                  (conv1): StdConv2dSame(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm1): GroupNormAct(\n",
       "                    32, 64, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv2): StdConv2dSame(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm2): GroupNormAct(\n",
       "                    32, 64, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv3): StdConv2dSame(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm3): GroupNormAct(\n",
       "                    32, 256, eps=1e-05, affine=True\n",
       "                    (act): Identity()\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                  (act3): ReLU(inplace=True)\n",
       "                )\n",
       "                (2): Bottleneck(\n",
       "                  (conv1): StdConv2dSame(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm1): GroupNormAct(\n",
       "                    32, 64, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv2): StdConv2dSame(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm2): GroupNormAct(\n",
       "                    32, 64, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv3): StdConv2dSame(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm3): GroupNormAct(\n",
       "                    32, 256, eps=1e-05, affine=True\n",
       "                    (act): Identity()\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                  (act3): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ResNetStage(\n",
       "              (blocks): Sequential(\n",
       "                (0): Bottleneck(\n",
       "                  (downsample): DownsampleConv(\n",
       "                    (conv): StdConv2dSame(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                    (norm): GroupNormAct(\n",
       "                      32, 512, eps=1e-05, affine=True\n",
       "                      (act): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (conv1): StdConv2dSame(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm1): GroupNormAct(\n",
       "                    32, 128, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv2): StdConv2dSame(128, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "                  (norm2): GroupNormAct(\n",
       "                    32, 128, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv3): StdConv2dSame(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm3): GroupNormAct(\n",
       "                    32, 512, eps=1e-05, affine=True\n",
       "                    (act): Identity()\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                  (act3): ReLU(inplace=True)\n",
       "                )\n",
       "                (1): Bottleneck(\n",
       "                  (conv1): StdConv2dSame(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm1): GroupNormAct(\n",
       "                    32, 128, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv2): StdConv2dSame(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm2): GroupNormAct(\n",
       "                    32, 128, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv3): StdConv2dSame(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm3): GroupNormAct(\n",
       "                    32, 512, eps=1e-05, affine=True\n",
       "                    (act): Identity()\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                  (act3): ReLU(inplace=True)\n",
       "                )\n",
       "                (2): Bottleneck(\n",
       "                  (conv1): StdConv2dSame(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm1): GroupNormAct(\n",
       "                    32, 128, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv2): StdConv2dSame(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm2): GroupNormAct(\n",
       "                    32, 128, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv3): StdConv2dSame(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm3): GroupNormAct(\n",
       "                    32, 512, eps=1e-05, affine=True\n",
       "                    (act): Identity()\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                  (act3): ReLU(inplace=True)\n",
       "                )\n",
       "                (3): Bottleneck(\n",
       "                  (conv1): StdConv2dSame(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm1): GroupNormAct(\n",
       "                    32, 128, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv2): StdConv2dSame(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm2): GroupNormAct(\n",
       "                    32, 128, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv3): StdConv2dSame(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm3): GroupNormAct(\n",
       "                    32, 512, eps=1e-05, affine=True\n",
       "                    (act): Identity()\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                  (act3): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ResNetStage(\n",
       "              (blocks): Sequential(\n",
       "                (0): Bottleneck(\n",
       "                  (downsample): DownsampleConv(\n",
       "                    (conv): StdConv2dSame(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                    (norm): GroupNormAct(\n",
       "                      32, 1024, eps=1e-05, affine=True\n",
       "                      (act): Identity()\n",
       "                    )\n",
       "                  )\n",
       "                  (conv1): StdConv2dSame(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm1): GroupNormAct(\n",
       "                    32, 256, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "                  (norm2): GroupNormAct(\n",
       "                    32, 256, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm3): GroupNormAct(\n",
       "                    32, 1024, eps=1e-05, affine=True\n",
       "                    (act): Identity()\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                  (act3): ReLU(inplace=True)\n",
       "                )\n",
       "                (1): Bottleneck(\n",
       "                  (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm1): GroupNormAct(\n",
       "                    32, 256, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm2): GroupNormAct(\n",
       "                    32, 256, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm3): GroupNormAct(\n",
       "                    32, 1024, eps=1e-05, affine=True\n",
       "                    (act): Identity()\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                  (act3): ReLU(inplace=True)\n",
       "                )\n",
       "                (2): Bottleneck(\n",
       "                  (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm1): GroupNormAct(\n",
       "                    32, 256, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm2): GroupNormAct(\n",
       "                    32, 256, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm3): GroupNormAct(\n",
       "                    32, 1024, eps=1e-05, affine=True\n",
       "                    (act): Identity()\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                  (act3): ReLU(inplace=True)\n",
       "                )\n",
       "                (3): Bottleneck(\n",
       "                  (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm1): GroupNormAct(\n",
       "                    32, 256, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm2): GroupNormAct(\n",
       "                    32, 256, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm3): GroupNormAct(\n",
       "                    32, 1024, eps=1e-05, affine=True\n",
       "                    (act): Identity()\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                  (act3): ReLU(inplace=True)\n",
       "                )\n",
       "                (4): Bottleneck(\n",
       "                  (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm1): GroupNormAct(\n",
       "                    32, 256, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm2): GroupNormAct(\n",
       "                    32, 256, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm3): GroupNormAct(\n",
       "                    32, 1024, eps=1e-05, affine=True\n",
       "                    (act): Identity()\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                  (act3): ReLU(inplace=True)\n",
       "                )\n",
       "                (5): Bottleneck(\n",
       "                  (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm1): GroupNormAct(\n",
       "                    32, 256, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm2): GroupNormAct(\n",
       "                    32, 256, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm3): GroupNormAct(\n",
       "                    32, 1024, eps=1e-05, affine=True\n",
       "                    (act): Identity()\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                  (act3): ReLU(inplace=True)\n",
       "                )\n",
       "                (6): Bottleneck(\n",
       "                  (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm1): GroupNormAct(\n",
       "                    32, 256, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm2): GroupNormAct(\n",
       "                    32, 256, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm3): GroupNormAct(\n",
       "                    32, 1024, eps=1e-05, affine=True\n",
       "                    (act): Identity()\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                  (act3): ReLU(inplace=True)\n",
       "                )\n",
       "                (7): Bottleneck(\n",
       "                  (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm1): GroupNormAct(\n",
       "                    32, 256, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm2): GroupNormAct(\n",
       "                    32, 256, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm3): GroupNormAct(\n",
       "                    32, 1024, eps=1e-05, affine=True\n",
       "                    (act): Identity()\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                  (act3): ReLU(inplace=True)\n",
       "                )\n",
       "                (8): Bottleneck(\n",
       "                  (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm1): GroupNormAct(\n",
       "                    32, 256, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                  (norm2): GroupNormAct(\n",
       "                    32, 256, eps=1e-05, affine=True\n",
       "                    (act): ReLU(inplace=True)\n",
       "                  )\n",
       "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "                  (norm3): GroupNormAct(\n",
       "                    32, 1024, eps=1e-05, affine=True\n",
       "                    (act): Identity()\n",
       "                  )\n",
       "                  (drop_path): Identity()\n",
       "                  (act3): ReLU(inplace=True)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (norm): Identity()\n",
       "          (head): ClassifierHead(\n",
       "            (global_pool): SelectAdaptivePool2d (pool_type=, flatten=False)\n",
       "            (fc): Identity()\n",
       "          )\n",
       "        )\n",
       "        (proj): Conv2d(1024, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      )\n",
       "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "      (blocks): ModuleList(\n",
       "        (0): Block(\n",
       "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): Block(\n",
       "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): Block(\n",
       "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): Block(\n",
       "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): Block(\n",
       "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): Block(\n",
       "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): Block(\n",
       "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): Block(\n",
       "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): Block(\n",
       "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): Block(\n",
       "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): Block(\n",
       "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): Block(\n",
       "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (attn): Attention(\n",
       "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "          (mlp): Mlp(\n",
       "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (act): GELU()\n",
       "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (drop): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (pre_logits): Identity()\n",
       "      (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       "    )\n",
       "    (act_postprocess1): Sequential(\n",
       "      (0): Identity()\n",
       "      (1): Identity()\n",
       "      (2): Identity()\n",
       "    )\n",
       "    (act_postprocess2): Sequential(\n",
       "      (0): Identity()\n",
       "      (1): Identity()\n",
       "      (2): Identity()\n",
       "    )\n",
       "    (act_postprocess3): Sequential(\n",
       "      (0): ProjectReadout(\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=1536, out_features=768, bias=True)\n",
       "          (1): GELU()\n",
       "        )\n",
       "      )\n",
       "      (1): Transpose()\n",
       "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
       "      (3): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "    )\n",
       "    (act_postprocess4): Sequential(\n",
       "      (0): ProjectReadout(\n",
       "        (project): Sequential(\n",
       "          (0): Linear(in_features=1536, out_features=768, bias=True)\n",
       "          (1): GELU()\n",
       "        )\n",
       "      )\n",
       "      (1): Transpose()\n",
       "      (2): Unflatten(dim=2, unflattened_size=torch.Size([24, 24]))\n",
       "      (3): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (4): Conv2d(768, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (scratch): Module(\n",
       "    (layer1_rn): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (layer2_rn): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (layer3_rn): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (layer4_rn): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (refinenet1): FeatureFusionBlock_custom(\n",
       "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (resConfUnit1): ResidualConvUnit_custom(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU()\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (resConfUnit2): ResidualConvUnit_custom(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU()\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (refinenet2): FeatureFusionBlock_custom(\n",
       "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (resConfUnit1): ResidualConvUnit_custom(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU()\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (resConfUnit2): ResidualConvUnit_custom(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU()\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (refinenet3): FeatureFusionBlock_custom(\n",
       "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (resConfUnit1): ResidualConvUnit_custom(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU()\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (resConfUnit2): ResidualConvUnit_custom(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU()\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (refinenet4): FeatureFusionBlock_custom(\n",
       "      (out_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (resConfUnit1): ResidualConvUnit_custom(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU()\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (resConfUnit2): ResidualConvUnit_custom(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (activation): ReLU()\n",
       "        (skip_add): FloatFunctional(\n",
       "          (activation_post_process): Identity()\n",
       "        )\n",
       "      )\n",
       "      (skip_add): FloatFunctional(\n",
       "        (activation_post_process): Identity()\n",
       "      )\n",
       "    )\n",
       "    (output_conv): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): Interpolate()\n",
       "      (2): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (3): ReLU(inplace=True)\n",
       "      (4): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (5): ReLU(inplace=True)\n",
       "      (6): Identity()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "if optimize == True and device == torch.device(\"cuda\"):\n",
    "    model = model.to(memory_format=torch.channels_last)\n",
    "    model = model.half()\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92e126ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get input\n",
    "img_names = glob.glob(os.path.join(input_path, \"*\"))\n",
    "num_images = len(img_names)\n",
    "\n",
    "# create output folder\n",
    "os.makedirs(output_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cf4b771",
   "metadata": {},
   "outputs": [],
   "source": [
    "kitti_crop = False\n",
    "absolute_depth = False\n",
    "\n",
    "# input\n",
    "img = np.random.rand(480,640,3)\n",
    "if kitti_crop is True:\n",
    "    height, width, _ = img.shape\n",
    "    top = height - 352\n",
    "    left = (width - 1216) // 2\n",
    "    img = img[top : top + 352, left : left + 1216, :]\n",
    "\n",
    "img_input = transform({\"image\": img})[\"image\"]\n",
    "\n",
    "sample = torch.from_numpy(img_input).to(device).unsqueeze(0)\n",
    "\n",
    "if optimize == True and device == torch.device(\"cuda\"):\n",
    "    sample = sample.to(memory_format=torch.channels_last)\n",
    "    sample = sample.half()\n",
    "\n",
    "start, end = None, None\n",
    "if device == torch.device('cuda'):\n",
    "    start, end = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "162a9c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom decoder step for CUDA timing\n",
    "def decoder(model, x):\n",
    "    \n",
    "    start, end = None, None\n",
    "    if torch.cuda.is_available(): # assumes availability = in use\n",
    "        start, end = torch.cuda.Event(enable_timing=True), torch.cuda.Event(enable_timing=True)\n",
    "    \n",
    "    b, c, h, w = x.shape\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        start.record()\n",
    "    else:\n",
    "        start = time.time()\n",
    "        \n",
    "    layer_1 = model.pretrained.activations[\"1\"]\n",
    "    layer_2 = model.pretrained.activations[\"2\"]\n",
    "    layer_3 = model.pretrained.activations[\"3\"]\n",
    "    layer_4 = model.pretrained.activations[\"4\"]\n",
    "\n",
    "    layer_1 = model.pretrained.act_postprocess1[0:2](layer_1)\n",
    "    layer_2 = model.pretrained.act_postprocess2[0:2](layer_2)\n",
    "    layer_3 = model.pretrained.act_postprocess3[0:2](layer_3)\n",
    "    layer_4 = model.pretrained.act_postprocess4[0:2](layer_4)\n",
    "\n",
    "    unflatten = nn.Sequential(\n",
    "        nn.Unflatten(\n",
    "            2,\n",
    "            torch.Size(\n",
    "                [\n",
    "                    h // model.pretrained.model.patch_size[1],\n",
    "                    w // model.pretrained.model.patch_size[0],\n",
    "                ]\n",
    "            ),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if layer_1.ndim == 3:\n",
    "        layer_1 = unflatten(layer_1)\n",
    "    if layer_2.ndim == 3:\n",
    "        layer_2 = unflatten(layer_2)\n",
    "    if layer_3.ndim == 3:\n",
    "        layer_3 = unflatten(layer_3)\n",
    "    if layer_4.ndim == 3:\n",
    "        layer_4 = unflatten(layer_4)\n",
    "\n",
    "    layer_1 = model.pretrained.act_postprocess1[3 : len(model.pretrained.act_postprocess1)](layer_1)\n",
    "    layer_2 = model.pretrained.act_postprocess2[3 : len(model.pretrained.act_postprocess2)](layer_2)\n",
    "    layer_3 = model.pretrained.act_postprocess3[3 : len(model.pretrained.act_postprocess3)](layer_3)\n",
    "    layer_4 = model.pretrained.act_postprocess4[3 : len(model.pretrained.act_postprocess4)](layer_4)\n",
    "\n",
    "    layer_1_rn = model.scratch.layer1_rn(layer_1)\n",
    "    layer_2_rn = model.scratch.layer2_rn(layer_2)\n",
    "    layer_3_rn = model.scratch.layer3_rn(layer_3)\n",
    "    layer_4_rn = model.scratch.layer4_rn(layer_4)\n",
    "\n",
    "    path_4 = model.scratch.refinenet4(layer_4_rn)\n",
    "    path_3 = model.scratch.refinenet3(path_4, layer_3_rn)\n",
    "    path_2 = model.scratch.refinenet2(path_3, layer_2_rn)\n",
    "    path_1 = model.scratch.refinenet1(path_2, layer_1_rn)\n",
    "\n",
    "    out = model.scratch.output_conv(path_1)\n",
    "    \n",
    "    elapsed = None\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        end.record()\n",
    "        torch.cuda.synchronize()\n",
    "        elapsed = start.elapsed_time(end)\n",
    "    else:\n",
    "        end = time.time()\n",
    "        elapsed = end - start\n",
    "\n",
    "    return out, elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf16dee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/cho/anaconda3/envs/dpt/lib/python3.7/site-packages/torch/nn/functional.py:3458: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  \"See the documentation of nn.Upsample for details.\".format(mode)\n"
     ]
    }
   ],
   "source": [
    "# warm up devices\n",
    "for _ in range(5):\n",
    "    _ = model.forward(sample)\n",
    "\n",
    "# compute\n",
    "with torch.no_grad():\n",
    "    for r in range(runs):\n",
    "        # time encoder\n",
    "        if device == torch.device('cuda'):\n",
    "            start.record()\n",
    "            _ = model.pretrained.model.forward_flex(sample)\n",
    "            end.record()\n",
    "            \n",
    "            torch.cuda.synchronize()\n",
    "            elapsed = start.elapsed_time(end)\n",
    "            timings[r,0] = elapsed\n",
    "            \n",
    "        else:\n",
    "            start = time.time()\n",
    "            _ = model.pretrained.model.forward_flex(sample)\n",
    "            end = time.time()\n",
    "            timings[r,0] = end - start\n",
    "            \n",
    "        # time decoder\n",
    "        _, elapsed = decoder(model, sample)\n",
    "        timings[r,1] = elapsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6463f0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.2860888452529906, 1.5152617864608764)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timings[:,0].mean(), timings[:,1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6050bd5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.056641852339901294, 0.03524424828392462)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timings[:,0].std(), timings[:,1].std()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
