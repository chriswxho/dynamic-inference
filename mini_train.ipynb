{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c1252a8d-7d5c-4977-8062-5305040720b4",
   "metadata": {},
   "source": [
    "## Model setup and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f2a2a0-b0ef-4e7f-9de7-5e7993ce12af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In[1]:\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import Compose\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "from dpt.plmodels import InteriorNetDPT\n",
    "from dpt.transforms import Resize, NormalizeImage, PrepareForNet\n",
    "from data.InteriorNetDataset import InteriorNetDataset\n",
    "from data.metrics import SILog, get_metrics\n",
    "from util.gpu_config import get_batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c569181-3948-4840-8a05-044f6ec86719",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# k8s paths\n",
    "k8s = True\n",
    "k8s_repo = r'opt/repo/dynamic-inference'\n",
    "k8s_pvc = r'christh9-pvc'\n",
    "\n",
    "# path settings\n",
    "input_path = 'input'\n",
    "output_path = 'output_monodepth'\n",
    "model_path = 'weights/dpt_hybrid_nyu-2ce69ec7.pt'\n",
    "dataset_path = 'video_inference_common/resources'\n",
    "logs_path = 'train-logs'\n",
    "\n",
    "if k8s:\n",
    "    input_path = os.path.join(k8s_repo, input_path)\n",
    "    output_path = os.path.join(k8s_repo, output_path)\n",
    "    model_path = os.path.join(k8s_pvc, 'dpt-hybrid-nyu.pt')\n",
    "    dataset_path = os.path.join(k8s_repo, dataset_path)\n",
    "    logs_dir = os.path.join(k8s_pvc, logs_path)\n",
    "    os.chdir('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb8e1fa-2f84-4e44-b4ce-3b1bbce9a197",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_w = 640\n",
    "net_h = 480\n",
    "\n",
    "normalization = NormalizeImage(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    \n",
    "transform = Compose(\n",
    "    [\n",
    "        Resize(\n",
    "            net_w,\n",
    "            net_h,\n",
    "            resize_target=None,\n",
    "            keep_aspect_ratio=True,\n",
    "            ensure_multiple_of=32,\n",
    "            resize_method=\"minimal\",\n",
    "            image_interpolation_method=cv2.INTER_CUBIC,\n",
    "        ),\n",
    "        normalization,\n",
    "        PrepareForNet(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd130f6-fe5b-4528-8d00-3e54f95855d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataloader\n",
    "\n",
    "start = time.time()\n",
    "    \n",
    "batch_size = get_batch_size(None)\n",
    "lr = 1e-4\n",
    "num_epochs = 200\n",
    "\n",
    "print('-- Hyperparams --')\n",
    "print(f'Batchsize: {batch_size}')\n",
    "print(f'Learning rate: {lr}')\n",
    "print(f'Epochs: {num_epochs}')\n",
    "print('-----------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c58e425-9a7f-48be-a2ea-78a48a9de609",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# model setup\n",
    "model = InteriorNetDPT(batch_size, lr, num_epochs, model_path)\n",
    "\n",
    "# logging setup\n",
    "exp_idx = len(list(filter(lambda f: '.pt' in f, os.listdir(os.path.join(logs_dir)))))\n",
    "\n",
    "# dataloader setup\n",
    "interiornet_dataset = InteriorNetDataset(dataset_path, transform=transform, subsample=True)\n",
    "dataloader = DataLoader(interiornet_dataset, \n",
    "                        batch_size=model.hparams.batch_size,\n",
    "                        shuffle=True,\n",
    "                        pin_memory=True,\n",
    "                        num_workers=4*torch.cuda.device_count() if torch.cuda.is_available() else 0)\n",
    "\n",
    "\n",
    "print(f'Created datasets in {timedelta(seconds=round(time.time()-start,2))}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e5335b-8cae-4b2f-a197-4d2491df74ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ddp doesn't work on jupyter\n",
    "if torch.cuda.is_available(): \n",
    "    trainer = pl.Trainer(gpus=torch.cuda.device_count(), \n",
    "                         max_epochs=model.hparams.num_epochs)\n",
    "else:\n",
    "    trainer = pl.Trainer(max_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f48b6f-046c-481a-9cef-3cace93708e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training')\n",
    "\n",
    "start = time.time()\n",
    "trainer.fit(model, dataloader)\n",
    "\n",
    "print(f'Training completed in {timedelta(seconds=round(time.time()-start,2))}')\n",
    "print(f'Training checkpoints and logs are saved in {trainer.log_dir}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a0a117-30e0-4f43-b21f-59d6e02665f6",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97b3236-f5a3-48f4-b287-ca783c5bd9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('dark_background')\n",
    "\n",
    "from util.validate_nyu import BadPixelMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8d6866-d3ea-44b2-b465-a01823dbce35",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "# compare to original model predictions\n",
    "original_model = InteriorNetDPT(batch_size, lr, num_epochs, model_path)\n",
    "original_model.to(device)\n",
    "print('Loaded original model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5068d012-ed00-4a70-a7fa-e34af5945e73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metric = BadPixelMetric()\n",
    "\n",
    "with torch.no_grad():\n",
    "    num_photos = len(interiornet_dataset)\n",
    "    for i,sample in enumerate(interiornet_dataset):\n",
    "        fig = plt.figure(figsize=(12,12))\n",
    "        \n",
    "        image, depth = torch.tensor(sample['image']).to(device), torch.tensor(sample['depth']).to(device)\n",
    "        out = model(image.unsqueeze(0))\n",
    "        out_nyu = original_model(image.unsqueeze(0)).squeeze(0)\n",
    "        print(f'Frame {i} finetune err:', metric(out, depth.unsqueeze(0), ~torch.isnan(depth.unsqueeze(0))).item())\n",
    "        print(f'Frame {i} NYU err:', metric(out_nyu, depth.unsqueeze(0), ~torch.isnan(depth.unsqueeze(0))).item())\n",
    "        \n",
    "        out, depth, out_nyu = out.squeeze(0).to('cpu'), depth.to('cpu'), out_nyu.to('cpu')\n",
    "        \n",
    "        for j,img in enumerate([out, depth, out_nyu]):\n",
    "            ax = fig.add_subplot(1,3,j+1)\n",
    "            if j == 0:\n",
    "                ax.set_ylabel(f'Frame {i}', rotation=0, size='large')\n",
    "            ax.imshow(img)\n",
    "            \n",
    "            ax.yaxis.set_label_coords(-0.2, 0.5)\n",
    "            ax.get_xaxis().set_ticks([])\n",
    "            ax.get_yaxis().set_ticks([])\n",
    "        \n",
    "        for ax,name in zip(fig.axes,['Finetuned', 'Truth', 'NYU']):\n",
    "            ax.set_title(name)\n",
    "                \n",
    "        fig.show()\n",
    "        \n",
    "        if i >= num_photos - 1: break\n",
    "        i += 1\n",
    "        \n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
