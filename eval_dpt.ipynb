{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a585abc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from dpt.plmodels import InteriorNetDPT\n",
    "from data.InteriorNetDataset import InteriorNetDataset\n",
    "from data.metrics import SILog, DepthMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f372449-6446-4196-9f84-e0fb734e4509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = 'christh9-pvc/train-logs/finetune/grads'\n",
    "# # ddp, no_ddp = os.listdir(path)\n",
    "# # ddp = torch.load(os.path.join(path,ddp))\n",
    "# # no_ddp = torch.load(os.path.join(path, no_ddp))\n",
    "# # for i in range(len(ddp)):\n",
    "# #     print(torch.all(ddp[i] == no_ddp[i]))\n",
    "# sorted(os.listdir(path))\n",
    "# horovod_1_path = os.path.join(path,'grads-single-horovod-0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e337738b-9cfe-4400-b6dc-b26a92840f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# horovod_single = torch.load(single_horovod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e5b8bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device name: A40\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'device name: {torch.cuda.get_device_name(0) if device != \"cpu\" else \"cpu\"}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e6aa853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k8s paths\n",
    "k8s = True\n",
    "k8s_repo = r'opt/repo/dynamic-inference'\n",
    "k8s_pvc = r'christh9-pvc'\n",
    "\n",
    "# path settings\n",
    "model_path = 'weights/dpt_hybrid_nyu-2ce69ec7.pt'\n",
    "dataset_path = 'video_inference_common/resources'\n",
    "logs_path = 'train-logs'\n",
    "\n",
    "checkpoint_name = 'version_290'\n",
    "\n",
    "if k8s:\n",
    "    model_path = os.path.join(k8s_pvc, 'dpt-hybrid-nyu.pt')\n",
    "    dataset_path = os.path.join(k8s_repo, dataset_path)\n",
    "    logs_path = os.path.join(k8s_pvc, logs_path)\n",
    "    \n",
    "    checkpoint_dir = os.path.join(logs_path, 'finetune', checkpoint_name, 'checkpoints')\n",
    "    \n",
    "    os.chdir('/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84974c62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# select a checkpoint path based on the ones available\n",
    "checkpoint_dir = 'lightning_logs/version_3/checkpoints'\n",
    "ckpts = os.listdir(checkpoint_dir)\n",
    "sorted(ckpts, key=lambda x: int(re.findall(r'\\d+', x)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af25ca41-bb69-4978-b105-fca27f5605f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35776/1477735819.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchosen_ckpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mckpts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mcheckpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchosen_ckpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "chosen_ckpt = ckpts[0]\n",
    "checkpoint_path = os.path.join(checkpoint_dir, chosen_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdd158d7-5021-4fbe-a004-fdf35f2df163",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InteriorNetDPT(batch_size=1, \n",
    "                       lr=0, \n",
    "                       num_epochs=0, \n",
    "                       model_path=checkpoint_path)\n",
    "\n",
    "model.to(device)\n",
    "model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9174c449",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'chosen_ckpt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_35776/1469133367.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDepthMetrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mepoch_num\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'\\d+'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchosen_ckpt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34mf'st-{epoch_num}.pt'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34mf'st-{epoch_num}.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'chosen_ckpt' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = InteriorNetDataset(dataset_path, split='val', \n",
    "                             transform='default', subsample=True)\n",
    "\n",
    "loader = DataLoader(dataset, batch_size=1)\n",
    "\n",
    "metrics = DepthMetrics()\n",
    "\n",
    "epoch_num = re.findall(r'\\d+', chosen_ckpt)[0]\n",
    "if f'st-{epoch_num}.pt' in os.listdir(os.path.dirname(checkpoint_dir)):\n",
    "    st = torch.load(os.path.join(os.path.dirname(checkpoint_dir), f'st-{epoch_num}.pt'))\n",
    "    if st['s'][0].numel() == 1:\n",
    "        s,t = torch.tensor(st['s']).mean(0), torch.tensor(st['t']).mean(0)\n",
    "    else:\n",
    "        s,t = torch.cat(st['s']).reshape(-1, *list(st['s'][0].shape)), torch.cat(st['t']).reshape(-1, *list(st['t'][0].shape))\n",
    "    s,t = s.to(device), t.to(device)\n",
    "else:\n",
    "    st = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c75a87f-66aa-4006-9f58-e9b9155b187a",
   "metadata": {},
   "outputs": [],
   "source": [
    "st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681dccbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in loader:\n",
    "        im, depth = batch['image'].to(device), batch['depth'].to(device)\n",
    "        out = model(im)\n",
    "        \n",
    "#         print(out.mean())\n",
    "#         acc = metrics(out, depth, st=(s,t) if st else None) # val_\n",
    "#         print(acc)\n",
    "\n",
    "        plt.imshow(im.squeeze(0).permute([1,2,0]).cpu())\n",
    "        plt.show()\n",
    "        plt.imshow(depth.squeeze(0).cpu())\n",
    "        plt.show()\n",
    "        plt.imshow(out.squeeze(0).cpu())\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbbe597-bccf-40e4-ba43-8eb2ed862fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f96266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with torch.no_grad():\n",
    "#     for i in np.random.randint(0,1000,10):\n",
    "#         sample = interiornet_dataset[i]\n",
    "#         image, depth = torch.tensor(sample['image']).to(device), 1/sample['depth']\n",
    "#         out = model(image.unsqueeze(0)).squeeze(0).to('cpu')\n",
    "              \n",
    "#         fig,axs = plt.subplots(1,2)\n",
    "#         axs[0].imshow((out - out.min()) / (out.max()-out.min()))\n",
    "#         axs[1].imshow(depth)\n",
    "#         plt.show()\n",
    "        \n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1fd2f42-e9f7-4549-9ede-c41b00ac99d1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "model = InteriorNetDPT(1,0,0,model_path, extractor='rn18')\n",
    "# original = InteriorNetDPT(1,0,0,model_path)\n",
    "\n",
    "model.to(device)\n",
    "# original.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a40af8b6-f4dd-43f6-a5d3-fd386acb7fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.ones((1,3,640,480)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57c1767d-8848-44fb-a760-d9c45ac6fcb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/functional.py:3451: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'3': tensor([[[ 9.2299e-01,  9.3345e-01,  1.0393e+00,  ..., -8.1179e-01,\n",
      "           1.6876e-01,  7.9964e-01],\n",
      "         [ 4.9796e-01, -5.8956e+00, -3.8405e+00,  ..., -2.1222e+00,\n",
      "          -2.1699e-01,  1.6136e+00],\n",
      "         [ 4.9839e-01, -5.8869e+00, -3.8635e+00,  ..., -2.1348e+00,\n",
      "          -2.1725e-01,  1.6256e+00],\n",
      "         ...,\n",
      "         [ 4.4820e-01,  2.3224e-01,  1.1890e-01,  ..., -2.2903e-01,\n",
      "           4.7740e-01, -1.3227e-01],\n",
      "         [ 4.4474e-01,  2.2313e-01,  8.4456e-02,  ..., -1.7782e-01,\n",
      "           4.9974e-01, -3.7022e-02],\n",
      "         [ 4.5588e-01,  2.1189e-01,  8.5682e-02,  ..., -1.6214e-01,\n",
      "           4.8760e-01, -4.6805e-03]]], device='cuda:0', grad_fn=<AddBackward0>), '4': tensor([[[ 7.9636e-01,  2.0049e+00,  8.5451e-01,  ..., -3.2847e-01,\n",
      "          -2.6496e-01,  1.8031e+00],\n",
      "         [ 2.5069e-01, -5.8533e+00, -3.2051e+00,  ..., -1.8061e+00,\n",
      "          -4.4380e-01,  2.1010e+00],\n",
      "         [ 2.4888e-01, -5.8471e+00, -3.2301e+00,  ..., -1.8192e+00,\n",
      "          -4.4310e-01,  2.1121e+00],\n",
      "         ...,\n",
      "         [ 4.0874e-02,  3.3407e-01,  1.6446e-01,  ...,  1.6899e+00,\n",
      "           1.2942e+00, -2.8017e-01],\n",
      "         [ 5.1690e-02,  2.0262e-01, -3.4174e-02,  ...,  1.7314e+00,\n",
      "           1.2004e+00, -1.3566e-01],\n",
      "         [ 1.9701e-01,  1.0170e-01, -2.6912e-01,  ...,  1.6979e+00,\n",
      "           1.0225e+00,  3.9381e-03]]], device='cuda:0', grad_fn=<AddBackward0>)}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_36552/2839004217.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/repo/dynamic-inference/dpt/plmodels.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/repo/dynamic-inference/dpt/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0minv_depth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvert\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/repo/dynamic-inference/dpt/models.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels_last\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0mlayer_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_vit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mlayer_1_rn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscratch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1_rn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer_1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/repo/dynamic-inference/dpt/vit.py\u001b[0m in \u001b[0;36mforward_vit\u001b[0;34m(pretrained, x)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0mlayer_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m     \u001b[0mlayer_2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0mlayer_3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"3\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '1'"
     ]
    }
   ],
   "source": [
    "z = model(x)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
